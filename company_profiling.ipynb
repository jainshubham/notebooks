{
 "metadata": {
  "name": "",
  "signature": "sha256:31b18698d28f8d1e771b1e746954682eb8592e4c6aaf6461a4ed31f7fc900694"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import os, sys\n",
      "from time import time\n",
      "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"web.settings\")\n",
      "#sys.path.append('/home/shubhamjain/devel/contifydeploy/')\n",
      "sys.path.append('/home/shubhamjain/devel/contifydeploy/contify-banking')\n",
      "\n",
      "from brief.models import Brief  \n",
      "from entry.models import Entry\n",
      "import settings\n",
      "from django.core.management.base import BaseCommand\n",
      "\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, HashingVectorizer\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from sklearn.preprocessing import Normalizer\n",
      "from sklearn import metrics\n",
      "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
      "import logging\n",
      "from optparse import OptionParser\n",
      "from time import time\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from random import random\n",
      "import nltk, math\n",
      "from optparse import make_option           \n",
      "from datetime import datetime, timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "Could not import settings 'contify-banking.settings' (Is it on sys.path?): No module named contify-banking.settings",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-17ffaba85bd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/shubhamjain/devel/contifydeploy/contify-banking'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbrief\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBrief\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEntry\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/shubhamjain/devel/contifydeploy/contify-banking/brief/models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0menum\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntEnum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdjango\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmptt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMPTTModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdjango\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultfilters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mslugify\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/shubhamjain/.pyenv/versions/ml_local/lib/python2.7/site-packages/django/db/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mDEFAULT_DB_ALIAS\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDATABASES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mImproperlyConfigured\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You must define a '%s' database\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mDEFAULT_DB_ALIAS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/shubhamjain/.pyenv/versions/ml_local/lib/python2.7/site-packages/django/utils/functional.pyc\u001b[0m in \u001b[0;36minner\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrapped\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/shubhamjain/.pyenv/versions/ml_local/lib/python2.7/site-packages/django/conf/__init__.pyc\u001b[0m in \u001b[0;36m_setup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Settings cannot be imported, because environment variable %s is undefined.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mENVIRONMENT_VARIABLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSettings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_settings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_settings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/shubhamjain/.pyenv/versions/ml_local/lib/python2.7/site-packages/django/conf/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, settings_module)\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSETTINGS_MODULE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not import settings '%s' (Is it on sys.path?): %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSETTINGS_MODULE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# Settings that should be converted into tuples if they're mistakenly entered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: Could not import settings 'contify-banking.settings' (Is it on sys.path?): No module named contify-banking.settings"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn import preprocessing\n",
      "\n",
      "X_train = np.array([\"new york is a hell of a town\",\n",
      "                    \"new york was originally dutch\",\n",
      "                    \"the big apple is great\",\n",
      "                    \"new york is also called the big apple\",\n",
      "                    \"nyc is nice\",\n",
      "                    \"people abbreviate new york city as nyc\",\n",
      "                    \"the capital of great britain is london\",\n",
      "                    \"london is in the uk\",\n",
      "                    \"london is in england\",\n",
      "                    \"london is in great britain\",\n",
      "                    \"it rains a lot in london\",\n",
      "                    \"london hosts the british museum\",\n",
      "                    \"new york is great and so is london\",\n",
      "                    \"i like london better than new york\"])\n",
      "y_train_text = [[\"new york\"],[\"new york\"],[\"new york\"],[\"new york\"],[\"new york\"],\n",
      "                [\"new york\"],[\"london\"],[\"london\"],[\"london\"],[\"london\"],\n",
      "                [\"london\"],[\"london\"],[\"new york\",\"london\"],[\"new york\",\"london\"]]\n",
      "\n",
      "X_test = np.array(['nice day in nyc',\n",
      "                   'welcome to london',\n",
      "                   'london is rainy',\n",
      "                   'it is raining in britian',\n",
      "                   'it is raining in britian and the big apple',\n",
      "                   'it is raining in britian and nyc',\n",
      "                   'hello welcome to new york. enjoy it here and london too'])\n",
      "target_names = ['New York', 'London']\n",
      "\n",
      "lb = preprocessing.LabelBinarizer()\n",
      "Y = lb.fit_transform(y_train_text)\n",
      "\n",
      "classifier = Pipeline([\n",
      "    ('vectorizer', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
      "\n",
      "classifier.fit(X_train, Y)\n",
      "predicted = classifier.predict(X_test)\n",
      "all_labels = lb.inverse_transform(predicted)\n",
      "\n",
      "for item, labels in zip(X_test, all_labels):\n",
      "    print '%s => %s' % (item, ', '.join(labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#important"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate the most frequent features first\n",
      "vect = TfidfVectorizer(vocabulary=emoticons)\n",
      "matrix = vect.fit_transform(traindata, max_features=10)\n",
      "top_features = vect.vocabulary_\n",
      "n = len(top_features)\n",
      "\n",
      "# insert the emoticons into the vocabulary of common features\n",
      "emoticons = {\":)\":0, \":P\":1, \":(\":2)}\n",
      "for feature, index in emoticons.items():\n",
      "    top_features[feature] = n + index\n",
      "\n",
      "# re-vectorize using both sets of features\n",
      "# at this point len(top_features) == 13\n",
      "vect = TfidfVectorizer(vocabulary=top_features)\n",
      "matrix = vect.fit_transform(traindata)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-3-9b71bdcb44f8>, line 8)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-9b71bdcb44f8>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    emoticons = {\":)\":0, \":P\":1, \":(\":2)}\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction import text\n",
      "\n",
      "my_additional_stop_words={'span', 'medium', 'border', 'double', 'style', 'class', 'fe00d6','image', 'resize', 'd38833', '00fe64', \n",
      "                          'td', 'padding', '10px', 'valign', 'tr', 'solid', '000000', '1px', 'tr', 'align', 'center',\n",
      "                          'aaa', 'aa', 'td', 'valign', 'tr', 'width', '255', '262', 'midas', 'em', 'h2', 'h3', 'font' 'h4' 'http',\n",
      "                          'img', 'src', 'newsimg', 'png', 'pics2', 'www', 'padding', '10px', '000000', '1px', 'tr', 'center', \n",
      "                          'valign', '255', '262', 'em', '000', 'com', 'alt', 'url', 'sm', 'li', 'elhajj', 'ul', 'wocc', 'xwv',\n",
      "                          'videoid', 'linkro', 'fp7', 'dxb'}\n",
      "#my_additional_stop_words={}   \n",
      "\n",
      "stop_words = text.ENGLISH_STOP_WORDS.union(my_additional_stop_words)\n",
      "\n",
      "item = Entry.objects.order_by(\"approved_on\")[:4000]\n",
      "#tempSoup= str(item[i].title+item[i].section+item[i].topic+item[i].industry+item[i].body_html+item[i].primary_topic+item[i].primary_industry+item[i].auto_tagged_topic+item[i].auto_tagged_industry)\n",
      "storySoup = item.values_list('body_html', flat=True)\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, HashingVectorizer\n",
      "vectorizer = CountVectorizer(stop_words=stop_words, binary=False)\n",
      "X = vectorizer.fit_transform(storySoup)\n",
      "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
      "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
      "from sklearn.decomposition import NMF\n",
      "nmf = NMF(n_components=50, random_state=1).fit(X)\n",
      "\n",
      "feature_names = vectorizer.get_feature_names()\n",
      "for topic_idx, topic in enumerate(nmf.components_):\n",
      "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vect = TfidfVectorizer(vocabulary=stop_words)\n",
      "matrix = vect.fit_transform(storySoup)\n",
      "top_features = vect.ngram_range"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hasher = HashingVectorizer(stop_words='english', non_negative=True,\n",
      "        norm=None, binary=False, vocabulary={'hdfc', 'hdfc bank', \n",
      "        'Aditya Puri', \t'HDFCBank.com', 'HDBFS', 'HSL'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}